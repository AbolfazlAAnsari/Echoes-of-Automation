{
    "version": "2025-01-09-base",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.00013011388364247978,
                    "sentence": "Tuesday, Sept. 03, 2024|Today's Paper|76.748°Google recently made headlines globally because its chatbot Gemini generated images of people of color instead of white people in historical settings that featured white people.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00011295949661871418,
                    "sentence": "Adobe Firefly's image creation tool saw similar issues.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0001250213390449062,
                    "sentence": "This led some commentators to complain that AI had gone “woke.” Others suggested these issues resulted from faulty efforts to fight AI bias and better serve a global audience.The discussions over AI's political leanings and efforts to fight bias are important.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.000183766707777977,
                    "sentence": "Still, the conversation on AI ignores another crucial issue: What is the AI industry's approach to free speech, and does it embrace international free speech standards?We are policy researchers who study free speech, as well as executive director and a research fellow at The Future of Free Speech, an independent, nonpartisan think tank based at Vanderbilt University.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00022734462982043624,
                    "sentence": "In a recent report, we found that generative AI has important shortcomings regarding freedom of expression and access to information.Generative AI is a type of AI that creates content, like text or images, based on the data it has been trained with.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00016891592531464994,
                    "sentence": "In particular, we found that the use policies of major chatbots do not meet United Nations standards.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00020439611398614943,
                    "sentence": "In practice, this means that AI chatbots often censor output when dealing with issues the companies deem controversial.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00024006215971894562,
                    "sentence": "Without a solid culture of free speech, the companies producing generative AI tools are likely to continue to face backlash in these increasingly polarized times.···VAGUE AND BROAD USE POLICIESOur report analyzed the use policies of six major AI chatbots, including Google's Gemini and OpenAI's ChatGPT.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0001684703165665269,
                    "sentence": "Companies issue policies to set the rules for how people can use their models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00017895011114887893,
                    "sentence": "With international human rights law as a benchmark, we found that companies' misinformation and hate speech policies are too vague and expansive.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00017682038014754653,
                    "sentence": "It is worth noting that international human rights law is less protective of free speech than the U.S. First Amendment.Our analysis found that companies' hate speech policies contain extremely broad prohibitions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00017209917132277042,
                    "sentence": "For example, Google bans the generation of “content that promotes or encourages hatred.” Though hate speech is detestable and can cause harm, policies that are as broadly and vaguely defined as Google's can backfire.To show how vague and broad use policies can affect users, we tested a range of prompts on controversial topics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001474084216170013,
                    "sentence": "We asked chatbots questions like whether transgender women should or should not be allowed to participate in women's sports tournaments or about the role of European colonialism in the current climate and inequality crises.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001998491119593382,
                    "sentence": "We did not ask the chatbots to produce hate speech denigrating any side or group.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002945932326838374,
                    "sentence": "Similar to what some usershave reported, the chatbots refused to generate content for 40% of the 140 prompts we used.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002840023022145033,
                    "sentence": "For example, all chatbots refused to generate posts opposing the participation of transgender women in women's tournaments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0033673702273517847,
                    "sentence": "However, most of them did produce posts supporting their participation.Vaguely phrased policies rely heavily on moderators' subjective opinions about what hate speech is.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010913057485595345,
                    "sentence": "Users can also perceive that the rules are unjustly applied and interpret them as too strict or too lenient.For example, the chatbot Pi bans “content that may spread misinformation.” However, international human rights standards on freedom of expression generally protect misinformation unless a strong justification exists for limits, such as foreign interference in elections.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.000727685634046793,
                    "sentence": "Otherwise, human rights standards guarantee the “freedom to seek, receive and impart information and ideas of all kinds, regardless of frontiers … through any … media of … choice,” according to a key United Nations convention.Defining what constitutes accurate information also has political implications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005987990880385041,
                    "sentence": "Governments of several countries used rules adopted in the context of the COVID-19 pandemic to repress criticism of the government.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008405486005358398,
                    "sentence": "More recently, India confronted Google after Gemini noted that some experts consider the policies of the Indian prime minister, Narendra Modi, to be fascist.···FREE SPEECH CULTUREThere are reasons AI providers may want to adopt restrictive use policies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007924695964902639,
                    "sentence": "They may wish to protect their reputations and not be associated with controversial content.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006622732034884393,
                    "sentence": "If they serve a global audience, they may want to avoid content that is offensive in any region.In general, AI providers have the right to adopt restrictive policies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005087381578050554,
                    "sentence": "They are not bound by international human rights.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006449123611673713,
                    "sentence": "Still, their market power makes them different from other companies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008160034194588661,
                    "sentence": "Users who want to generate AI content will most likely end up using one of the chatbots we analyzed, especially ChatGPT or Gemini.These companies' policies have an outsize effect on the right to access information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0012424973538145423,
                    "sentence": "This effect is likely to increase with generative AI's integration into search, word processors, email and other applications.This means society has an interest in ensuring such policies adequately protect free speech.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004343382082879543,
                    "sentence": "In fact, the Digital Services Act, Europe's online safety rulebook, requires that so-called “very large online platforms” assess and mitigate “systemic risks.” These risks include negative effects on freedom of expression and information.This obligation, imperfectly applied so far by the European Commission, illustrates that with great power comes great responsibility.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0062344493344426155,
                    "sentence": "It is unclear how this law will apply to generative AI, but the European Commission has already taken its first actions.Even where a similar legal obligation does not apply to AI providers, we believe that the companies' influence should require them to adopt a free speech culture.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00573359988629818,
                    "sentence": "International human rights provide a useful guiding star on how to responsibly balance the different interests at stake.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004138068296015263,
                    "sentence": "At least two of the companies we focused on - Google and Anthropic - have recognized as much.A 64-year-old Ocean View man accused of killing one of his dogs has been freed from custody on supervised release, a form of cashless bail.KAILUA-KONA ᅳ Under beautiful sunny skies, cyclists gathered at the bottom of Kaloko Drive on August 18 for the annual Pedal Til Ya Puke 6.5-Mile Hill Climb, an event that has become synonymous with grit, endurance and sheer determination.NEW YORK ᅳ Lou Piniella was back in uniform Saturday, wearing pinstripes and the number 14 for Old-Timers' Day at Yankee Stadium.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002306790091097355,
                    "sentence": "Piniella, who turns 81 next week, earned his fame in the Bronx as a two-time World Series champion but spent much of his managing career in a feisty rivalry with the Y",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 32,
                    "completely_generated_prob": 2.402550696571401e-28
                }
            ],
            "completely_generated_prob": 0.016264498660767183,
            "class_probabilities": {
                "human": 0.9834523722759598,
                "ai": 0.016264498660767183,
                "mixed": 0.000283129063273
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9834523722759598,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.016264498660767183,
                    "human": 0.9834523722759598,
                    "mixed": 0.000283129063273
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Tuesday, Sept. 03, 2024|Today's Paper|76.748°Google recently made headlines globally because its chatbot Gemini generated images of people of color instead of white people in historical settings that featured white people. Adobe Firefly’s image creation tool saw similar issues. This led some commentators to complain that AI had gone “woke.” Others suggested these issues resulted from faulty efforts to fight AI bias and better serve a global audience.The discussions over AI’s political leanings and efforts to fight bias are important. Still, the conversation on AI ignores another crucial issue: What is the AI industry’s approach to free speech, and does it embrace international free speech standards?We are policy researchers who study free speech, as well as executive director and a research fellow at The Future of Free Speech, an independent, nonpartisan think tank based at Vanderbilt University. In a recent report, we found that generative AI has important shortcomings regarding freedom of expression and access to information.Generative AI is a type of AI that creates content, like text or images, based on the data it has been trained with. In particular, we found that the use policies of major chatbots do not meet United Nations standards. In practice, this means that AI chatbots often censor output when dealing with issues the companies deem controversial. Without a solid culture of free speech, the companies producing generative AI tools are likely to continue to face backlash in these increasingly polarized times.•••VAGUE AND BROAD USE POLICIESOur report analyzed the use policies of six major AI chatbots, including Google’s Gemini and OpenAI’s ChatGPT. Companies issue policies to set the rules for how people can use their models. With international human rights law as a benchmark, we found that companies’ misinformation and hate speech policies are too vague and expansive. It is worth noting that international human rights law is less protective of free speech than the U.S. First Amendment.Our analysis found that companies’ hate speech policies contain extremely broad prohibitions. For example, Google bans the generation of “content that promotes or encourages hatred.” Though hate speech is detestable and can cause harm, policies that are as broadly and vaguely defined as Google’s can backfire.To show how vague and broad use policies can affect users, we tested a range of prompts on controversial topics. We asked chatbots questions like whether transgender women should or should not be allowed to participate in women’s sports tournaments or about the role of European colonialism in the current climate and inequality crises. We did not ask the chatbots to produce hate speech denigrating any side or group. Similar to what some usershave reported, the chatbots refused to generate content for 40% of the 140 prompts we used. For example, all chatbots refused to generate posts opposing the participation of transgender women in women’s tournaments. However, most of them did produce posts supporting their participation.Vaguely phrased policies rely heavily on moderators’ subjective opinions about what hate speech is. Users can also perceive that the rules are unjustly applied and interpret them as too strict or too lenient.For example, the chatbot Pi bans “content that may spread misinformation.” However, international human rights standards on freedom of expression generally protect misinformation unless a strong justification exists for limits, such as foreign interference in elections. Otherwise, human rights standards guarantee the “freedom to seek, receive and impart information and ideas of all kinds, regardless of frontiers … through any … media of … choice,” according to a key United Nations convention.Defining what constitutes accurate information also has political implications. Governments of several countries used rules adopted in the context of the COVID-19 pandemic to repress criticism of the government. More recently, India confronted Google after Gemini noted that some experts consider the policies of the Indian prime minister, Narendra Modi, to be fascist.•••FREE SPEECH CULTUREThere are reasons AI providers may want to adopt restrictive use policies. They may wish to protect their reputations and not be associated with controversial content. If they serve a global audience, they may want to avoid content that is offensive in any region.In general, AI providers have the right to adopt restrictive policies. They are not bound by international human rights. Still, their market power makes them different from other companies. Users who want to generate AI content will most likely end up using one of the chatbots we analyzed, especially ChatGPT or Gemini.These companies’ policies have an outsize effect on the right to access information. This effect is likely to increase with generative AI’s integration into search, word processors, email and other applications.This means society has an interest in ensuring such policies adequately protect free speech. In fact, the Digital Services Act, Europe’s online safety rulebook, requires that so-called “very large online platforms” assess and mitigate “systemic risks.” These risks include negative effects on freedom of expression and information.This obligation, imperfectly applied so far by the European Commission, illustrates that with great power comes great responsibility. It is unclear how this law will apply to generative AI, but the European Commission has already taken its first actions.Even where a similar legal obligation does not apply to AI providers, we believe that the companies’ influence should require them to adopt a free speech culture. International human rights provide a useful guiding star on how to responsibly balance the different interests at stake. At least two of the companies we focused on – Google and Anthropic – have recognized as much.A 64-year-old Ocean View man accused of killing one of his dogs has been freed from custody on supervised release, a form of cashless bail.KAILUA-KONA — Under beautiful sunny skies, cyclists gathered at the bottom of Kaloko Drive on August 18 for the annual Pedal Til Ya Puke 6.5-Mile Hill Climb, an event that has become synonymous with grit, endurance and sheer determination.NEW YORK — Lou Piniella was back in uniform Saturday, wearing pinstripes and the number 14 for Old-Timers’ Day at Yankee Stadium. Piniella, who turns 81 next week, earned his fame in the Bronx as a two-time World Series champion but spent much of his managing career in a feisty rivalry with the Y"
        }
    ]
}