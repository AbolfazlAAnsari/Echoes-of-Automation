{
    "version": "2025-01-09-base",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.009034625254571438,
                    "sentence": "The recently leaked Facebook Papers have deepened the public understanding about the harms embedded in our digital environment, and the policy debate about how to make platform companies more transparent and accountable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012448379769921303,
                    "sentence": "Two recurring themes involve the effect of Facebook's products on children.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017248256132006645,
                    "sentence": "Leaked internal research(https://www.washingtonpost.com/technology/2021/10/25/what-are-the-facebook-papers/)(https://www.washingtonpost.com/technology/2021/10/25/what-are-the-facebook-papers/)demonstrates that they have knowledge of harm caused, and leaked communications show how Facebook planned to target children as young as six years old(https://www.nbcnews.com/tech/social-media/facebook-documents-reveal-company-targeted-children-young-6-rcna4021?cid=sm_npd_nn_tw_ma) as their next consumer base.For many, the Facebook Papers confirmed what researchers and caregivers have known for years - children may not be entirely safe online.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014933362603187561,
                    "sentence": "But they can be.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018578026443719864,
                    "sentence": "This is just the latest in a series of industry findings(https://www.wsj.com/articles/facebook-knows-instagram-is-toxic-for-teen-girls-company-documents-show-11631620739?mod=article_inline) about the impacts of digital technology on children and youth that have prompted Senate(https://www.commerce.senate.gov/2021/9/protecting-kids-online-facebook-instagram-and-mental-health-harms)hearings focused on \"Protecting Kids Online,\" Many are simply calling for rights and protections that we already afford to children offline, including freedom of expression and privacy and protections from undue harm.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1718166023492813,
                    "sentence": "However, children are also exposed to a bevy of new potential risks that are magnified by the sheer scale of companies like Facebook and TikTok, such as overtly targeted ads(https://www.techtransparencyproject.org/articles/facebooks-repeat-fail-harmful-teen-ads) for teens or new kinds of subtle(http://mediatechdemocracy.com/work/kidfluencers-unboxing-the-governance-cap-in-childrens-deceptive-advertising)advertising(http://mediatechdemocracy.com/work/kidfluencers-unboxing-the-governance-cap-in-childrens-deceptive-advertising) through \"kidfluencer\" content aimed at children as young as six or seven.In parallel, platforms and the services children use daily are designed largely without kids' needs or rights in mind.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12160730361938477,
                    "sentence": "In fact, most ignore children as a specific category of users altogether, despite global consensus that kids are disproportionately affected online, given that both their development and early use of digital technologies shape their experiences online.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11471939086914062,
                    "sentence": "Children and young people are simply treated as adults(https://5rightsfoundation.com/about-us/ ).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21031568944454193,
                    "sentence": "But because of their age and capacity, children cannot advocate on behalf of their own interests, or provide meaningful consent to how their data is used.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14910303056240082,
                    "sentence": "In response to public concern, Facebook recently paused its plans to build spaces entirely devoted to children.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21004067361354828,
                    "sentence": "But it is clear they see children as a growth market, so this pause is unlikely to endure.This is precisely why governments and children's rights experts around the world are calling for the 'best interest of the child' to be a primary consideration in all decisions to regulate online activity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9367368221282959,
                    "sentence": "Set out by the United Nations Convention on the Rights of the Child(https://ico.org.uk/for-organisations/childrens-code-hub/additional-resources/the-united-nations-convention-on-the-rights-of-the-child/), the best interests of children include safety, health and freedom of expression, but importantly, they also include wellbeing, psychological and emotional development, identity, and the freedom to form individual views.The United Kingdom is leading the charge to safeguard children's rights.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9643819332122803,
                    "sentence": "Their recently passed Children's Code (Age Appropriate Design Code) makes it very difficult for companies to collect, share and use children's data while giving anyone under 18 the utmost privacy over their personal data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9634052515029907,
                    "sentence": "The UK has shown that it takes the best interest of children seriously - especially when they stand in contrast to commercial interest.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.970564067363739,
                    "sentence": "In fact, the Children's Code mandates websites and apps prioritize these interests into their very design of any online services likely to be accessed by anyone under 18 - not just into kids apps - or face fines of up to four per cent of annual global revenue.And these new regulations are starting to work, spurring to a wave of industry changes(https://5rightsfoundation.com/Raftoftechchangestoprotectchildrenasnewrulescomeintoforce.pdf) that law and policymakers have been calling for years: Instagram will no longer allow unknown adults to direct message users under 18, YouTube will no longer use its auto-play feature to feed children endless videos, and Google has announced it will stop targeting advertising to those under 18.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009385418146848679,
                    "sentence": "These changes demonstrate the potential of using data protection to get at the heart of platforms' core business model, a strategy that Europe has embraced.Charlie Angus: Parliament must protect Canadians' rights online(https://nationalpost.com/opinion/charlie-angus-parliament-must-protect-canadians-rights-online)Sabrina Maddeaux: If Facebook whistleblower was Canadian, she may never have come forward(https://nationalpost.com/opinion/sabrina-maddeaux-if-facebook-whistleblower-was-canadian-she-may-never-have-come-forward)As of right now, Canada lacks any meaningful policies that specifically ensure children's rights are protected and empowered online.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.048403847962617874,
                    "sentence": "Earlier this year, the Alliance for Protecting Children's Rights and Safety Online addressed specific recommendations(https://theartofthepossible.ca/wp-content/uploads/2021/03/Letter-to-PM-APCRSO.pdf) to proactively protect children from harm to Prime Minister Justin Trudeau.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.052187688648700714,
                    "sentence": "Despite their efforts, and despite Canada being a signatory of the UN Convention on the Rights of the Child, the federal government has yet to uphold its duty to give children special protections in its upcoming legislation to address harmful content online.The revisions to the proposed online harms bill offer an opportunity to include child-specific legislation that includes standards for companies to follow age-appropriate(https://ico.org.uk/for-organisations/guide-to-data-protection/ico-codes-of-practice/age-appropriate-design-a-code-of-practice-for-online-services/standards-of-age-appropriate-design/) design.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.163552924990654,
                    "sentence": "Canada could follow the UK's footsteps and include \"services likely to be accessed by children\" as one of three separate categories of harm.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018939875066280365,
                    "sentence": "The duties for this children-specific category could then be broken down to include specific requirements for different age groups as well as preventing children of any age from encountering harmful content.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022702526301145554,
                    "sentence": "Norway has recently cracked down on one type of harmful content that promotes unrealistic body image standards to children.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014285920187830925,
                    "sentence": "Online ads that have been photoshopped(https://www.buzzfeednews.com/article/adeonibada/influencers-norway-law-filter-photoshop) or otherwise manipulated now have to be legally disclosed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02061089687049389,
                    "sentence": "This change reflects a growing global movement to prevent self-harms, harms to mental health, identity and body image that Canada could implement by requiring similar disclosures, especially to the youngest users.Canada could also impose greater accountability mechanisms for preventing harm before they occur, such as child safety and wellbeing risk assessments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05064719170331955,
                    "sentence": "These measures should account not only for harmful content but for the systems which promote and amplify the spread of harmful content, including algorithms.But online content regulation is simply not enough.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.061090774834156036,
                    "sentence": "As the UK demonstrates, these protections need to be built in to the very design of platforms and online services.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04205406457185745,
                    "sentence": "More robust data governance(https://medium.com/berkman-klein-center/why-all-data-governance-needs-to-consider-childrens-rights-8b218a825a08)and privacy reform will be needed to address the sheer scale of how children's data are collected and shared online, especially as they move more of their daily activities online during the pandemic.If the argument for better online spaces for children and youth and more privacy and empowerment over their online activities holds any merit, then it also begs the question: why aren't we all afforded the same protections online?Taylor Owen is Associate Professor and Director of the Centre for Media Technology and Democracy at McGill University.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.030161142349243164,
                    "sentence": "Sonja Solomun is the Director of Research at the Centre for Media Technology and Democracy at McGill University.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009601803496479988,
                    "sentence": "!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008373428136110306,
                    "sentence": "@COPYRIGHT=© 2021 Postmedia Network Inc. All rights reserved.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 29,
                    "completely_generated_prob": 1.0570721129595992e-19
                }
            ],
            "completely_generated_prob": 0.11117960964635752,
            "class_probabilities": {
                "human": 0.888453242841436,
                "ai": 0.11117960964635752,
                "mixed": 0.00036714751220645104
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.888453242841436,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.11117960964635752,
                    "human": 0.888453242841436,
                    "mixed": 0.00036714751220645104
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The recently leaked Facebook Papers have deepened the public understanding about the harms embedded in our digital environment, and the policy debate about how to make platform companies more transparent and accountable. Two recurring themes involve the effect of Facebook's products on children. Leaked internal research(https://www.washingtonpost.com/technology/2021/10/25/what-are-the-facebook-papers/)(https://www.washingtonpost.com/technology/2021/10/25/what-are-the-facebook-papers/)demonstrates that they have knowledge of harm caused, and leaked communications show how Facebook planned to target children as young as six years old(https://www.nbcnews.com/tech/social-media/facebook-documents-reveal-company-targeted-children-young-6-rcna4021?cid=sm_npd_nn_tw_ma) as their next consumer base.For many, the Facebook Papers confirmed what researchers and caregivers have known for years - children may not be entirely safe online. But they can be. This is just the latest in a series of industry findings(https://www.wsj.com/articles/facebook-knows-instagram-is-toxic-for-teen-girls-company-documents-show-11631620739?mod=article_inline) about the impacts of digital technology on children and youth that have prompted Senate(https://www.commerce.senate.gov/2021/9/protecting-kids-online-facebook-instagram-and-mental-health-harms)hearings focused on \"Protecting Kids Online,\" Many are simply calling for rights and protections that we already afford to children offline, including freedom of expression and privacy and protections from undue harm. However, children are also exposed to a bevy of new potential risks that are magnified by the sheer scale of companies like Facebook and TikTok, such as overtly targeted ads(https://www.techtransparencyproject.org/articles/facebooks-repeat-fail-harmful-teen-ads) for teens or new kinds of subtle(http://mediatechdemocracy.com/work/kidfluencers-unboxing-the-governance-cap-in-childrens-deceptive-advertising)advertising(http://mediatechdemocracy.com/work/kidfluencers-unboxing-the-governance-cap-in-childrens-deceptive-advertising) through \"kidfluencer\" content aimed at children as young as six or seven.In parallel, platforms and the services children use daily are designed largely without kids' needs or rights in mind. In fact, most ignore children as a specific category of users altogether, despite global consensus that kids are disproportionately affected online, given that both their development and early use of digital technologies shape their experiences online. Children and young people are simply treated as adults(https://5rightsfoundation.com/about-us/ ). But because of their age and capacity, children cannot advocate on behalf of their own interests, or provide meaningful consent to how their data is used. In response to public concern, Facebook recently paused its plans to build spaces entirely devoted to children. But it is clear they see children as a growth market, so this pause is unlikely to endure.This is precisely why governments and children's rights experts around the world are calling for the 'best interest of the child' to be a primary consideration in all decisions to regulate online activity. Set out by the United Nations Convention on the Rights of the Child(https://ico.org.uk/for-organisations/childrens-code-hub/additional-resources/the-united-nations-convention-on-the-rights-of-the-child/), the best interests of children include safety, health and freedom of expression, but importantly, they also include wellbeing, psychological and emotional development, identity, and the freedom to form individual views.The United Kingdom is leading the charge to safeguard children's rights. Their recently passed Children's Code (Age Appropriate Design Code) makes it very difficult for companies to collect, share and use children's data while giving anyone under 18 the utmost privacy over their personal data. The UK has shown that it takes the best interest of children seriously - especially when they stand in contrast to commercial interest. In fact, the Children's Code mandates websites and apps prioritize these interests into their very design of any online services likely to be accessed by anyone under 18 - not just into kids apps - or face fines of up to four per cent of annual global revenue.And these new regulations are starting to work, spurring to a wave of industry changes(https://5rightsfoundation.com/Raftoftechchangestoprotectchildrenasnewrulescomeintoforce.pdf) that law and policymakers have been calling for years: Instagram will no longer allow unknown adults to direct message users under 18, YouTube will no longer use its auto-play feature to feed children endless videos, and Google has announced it will stop targeting advertising to those under 18. These changes demonstrate the potential of using data protection to get at the heart of platforms' core business model, a strategy that Europe has embraced.Charlie Angus: Parliament must protect Canadians' rights online(https://nationalpost.com/opinion/charlie-angus-parliament-must-protect-canadians-rights-online)Sabrina Maddeaux: If Facebook whistleblower was Canadian, she may never have come forward(https://nationalpost.com/opinion/sabrina-maddeaux-if-facebook-whistleblower-was-canadian-she-may-never-have-come-forward)As of right now, Canada lacks any meaningful policies that specifically ensure children's rights are protected and empowered online. Earlier this year, the Alliance for Protecting Children's Rights and Safety Online addressed specific recommendations(https://theartofthepossible.ca/wp-content/uploads/2021/03/Letter-to-PM-APCRSO.pdf) to proactively protect children from harm to Prime Minister Justin Trudeau. Despite their efforts, and despite Canada being a signatory of the UN Convention on the Rights of the Child, the federal government has yet to uphold its duty to give children special protections in its upcoming legislation to address harmful content online.The revisions to the proposed online harms bill offer an opportunity to include child-specific legislation that includes standards for companies to follow age-appropriate(https://ico.org.uk/for-organisations/guide-to-data-protection/ico-codes-of-practice/age-appropriate-design-a-code-of-practice-for-online-services/standards-of-age-appropriate-design/) design. Canada could follow the UK's footsteps and include \"services likely to be accessed by children\" as one of three separate categories of harm. The duties for this children-specific category could then be broken down to include specific requirements for different age groups as well as preventing children of any age from encountering harmful content. Norway has recently cracked down on one type of harmful content that promotes unrealistic body image standards to children. Online ads that have been photoshopped(https://www.buzzfeednews.com/article/adeonibada/influencers-norway-law-filter-photoshop) or otherwise manipulated now have to be legally disclosed. This change reflects a growing global movement to prevent self-harms, harms to mental health, identity and body image that Canada could implement by requiring similar disclosures, especially to the youngest users.Canada could also impose greater accountability mechanisms for preventing harm before they occur, such as child safety and wellbeing risk assessments. These measures should account not only for harmful content but for the systems which promote and amplify the spread of harmful content, including algorithms.But online content regulation is simply not enough. As the UK demonstrates, these protections need to be built in to the very design of platforms and online services. More robust data governance(https://medium.com/berkman-klein-center/why-all-data-governance-needs-to-consider-childrens-rights-8b218a825a08)and privacy reform will be needed to address the sheer scale of how children's data are collected and shared online, especially as they move more of their daily activities online during the pandemic.If the argument for better online spaces for children and youth and more privacy and empowerment over their online activities holds any merit, then it also begs the question: why aren't we all afforded the same protections online?Taylor Owen is Associate Professor and Director of the Centre for Media Technology and Democracy at McGill University. Sonja Solomun is the Director of Research at the Centre for Media Technology and Democracy at McGill University. !@COPYRIGHT=© 2021 Postmedia Network Inc. All rights reserved."
        }
    ]
}