{
    "version": "2025-01-09-base",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.000189334707101807,
                    "sentence": "(CNN) &#8212; In the 1968 film \"2001: A Space Odyssey,\" audiences found themselves staring at one of the first modern depictions of an extremely polite but uncooperative artificial intelligence system, a character named HAL.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004012493009213358,
                    "sentence": "Given a direct request by the sole surviving astronaut to let him back in the spaceship,HAL responds: \"I'm sorry, Dave.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004213981155771762,
                    "sentence": "I'm afraid I can't do that.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00024253787705674767,
                    "sentence": "\"Recently, some users found themselves with a similarly (though less dramatic) polite refusal from Gemini, an integratedchatbot and AI assistantthat Google rolled out as a competitor to OpenAI'sChatGPT.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0001678253902355209,
                    "sentence": "When asked, Gemini politely refused in some instances to generate images of historically White people,such as the Vikings.Unlike the fictional HAL, Google's Gemini at leastoffered some explanation, saying that only showing images of White persons would reinforce \"harmful stereotypes and generalizations about people based on their race,\" according to Fox News Digital.The situation quickly erupted, with some critics dubbing it a\"woke\" AI scandal.It didn't help when users discovered that Gemini was creating diverse but historically inaccurate images.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00011411833111196756,
                    "sentence": "When prompted to depict America'sFounding Fathers, for example, it generated an image of a Black man.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00012268875434529036,
                    "sentence": "It also depicteda brown womanas the Pope, andvarious people of color, including a Black man, in Nazi uniformswhen asked to depict a 1943 German soldier.The backlash online was so swift that Google CEO Sundar Pichai admitted that Gemini hadoffended some of its users.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 7.702950824750587e-05,
                    "sentence": "Google also hit pause on Gemini's ability to generate people in images.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 8.425255509791896e-05,
                    "sentence": "It was presented to the public as a simple oversight done with good intentions gone wrong, withGoogle explaining in a blog postthat \"we tuned it to ensure it doesn't fall into some of the traps we've seen in the past with image generation technology.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 6.865247269161046e-05,
                    "sentence": "\"Those \"traps\" - for which Google overcorrected - were of course clear bias in previous AI systems (which are built on the same kinds of tech that Gemini is).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0001412534184055403,
                    "sentence": "These systems had a tendency to showbias against minorities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00028332171496003866,
                    "sentence": "Facial recognition software didn't always recognize Black people, for example, or evenlabeled themas \"gorillas.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003587609971873462,
                    "sentence": "Loan approval AI algorithmsended up showing bias against minorities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0250739473849535,
                    "sentence": "In the image space, if you asked previous AI image generators for an image of a CEO or a doctor, they initiallyalmost always showed images of White males.Ironically,Google was criticized in 2020 for firing a Black AI scientistwho asserted that its AI efforts were biased, and this backlashmay have contributed to the company's overcorrection in the other direction with Gemini.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.047161929309368134,
                    "sentence": "The underlying problem that Google is trying to solve is not an easy one.Historically, many new technological products have shown biases.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06070144101977348,
                    "sentence": "These can range from howbiomedical devices measure blood oxygen levelsfor different ethnic groups, resulting in underdiagnosis of certain conditions for Black patients, to howsensors don't always register darker-skinned individualsand the lack ofwomen in clinical drug trials.In the case of AI, this problem is exacerbated because of biases that exist in the training data - usually public data on the internet - which the AI tool then learns.The latest scandal, in which Gemini appears to value diversity over historical accuracy, may have uncovered a much bigger issue.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03989662230014801,
                    "sentence": "If Big Tech organizations such as Google, which have become the new gatekeepers to the world's information, are manipulating historical information based on possible ideological beliefs and cultural edicts, what else are they willing to change?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04350937157869339,
                    "sentence": "In other words, have Google and other Big Tech companies been manipulating information, including search results, about the present or the past because of ideology, cultures or government censorship?In the 21st century, forget censoring films, burning books or creating propaganda films as forms of information control.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03169654682278633,
                    "sentence": "Those are so 20th century.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04007132351398468,
                    "sentence": "Today, if it ain't on Google, it might as well not exist.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03432768955826759,
                    "sentence": "In this technology-driven world, search engines can be the most effective tool for censorship about the present and the past.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.057051315903663635,
                    "sentence": "To quote a Party slogan from George Orwell's \"1984,\" \"Who controls the past controls the future: who controls the present controls the past.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.056888140738010406,
                    "sentence": "\"As AI becomes more sophisticated, these fears of Big Tech censorship and manipulation of information (with or without the participation of governments) will only grow.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1008915901184082,
                    "sentence": "Conversational AI such as ChatGPT may already be replacing search as thepreferred method to find and summarize information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07781850546598434,
                    "sentence": "BothGoogleandMicrosoftsaw this possibility and jumped all in on AIafter the success of ChatGPT.The possibility even led The Economist to ask, with respect to AI, \"Is Google's 20-year dominance of search in peril?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006792411440983415,
                    "sentence": "\"Apple has been looking atincorporating OpenAI and more recently, Gemini, into new versions of its iPhones, which would mean significantly more people would use AI on a regular basis.As a professor, I already see this trend firsthand with my students.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009217869956046343,
                    "sentence": "They often prefer to use ChatGPT not only to find but also to summarize information for them in paragraphs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007254831143654883,
                    "sentence": "To the younger generation, because of AI, Web search engines are rapidly becoming as antiquated as physical card catalogs are in libraries today.What makes censorship and manipulation worse with AI is that today's AI already has a well-knownhallucination problem.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006797343958169222,
                    "sentence": "In other words, sometimes AI makes things up.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005796969053335488,
                    "sentence": "I learned this fact the hard way when students began turning in obviously AI-generated assignments, complete with references that looked great but had one problem: They didn't actually exist.Given the hallucination problem, whoever the leaders of AI are in the future (whether Google, Microsoft, OpenAI or a new company) will be tempted to \"fill in\" their own rules for what AI should and shouldn't produce, just like Google did with Gemini.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004508898709900677,
                    "sentence": "This \"filling in\" will inevitably come from the biases and culture of each company and could eventually restrict or at least drastically modify what AI is allowed or is willing to show us, just like Google did with Gemini.That's why this one little scandal goes beyond excessive diversity, equity and inclusion, or DEI, enthusiasm in one company.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006601029890589416,
                    "sentence": "It may be a portent of what's to come with AI and Big Tech leading us into Orwellian territory.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0011691221734508872,
                    "sentence": "In a few years, you may just want to ask your friendly AI companion to give you some historical information, only to have the AI respond in that maddeningly polite way: \"I'm sorry, Dave.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0013015889562666416,
                    "sentence": "I'm afraid I can't do that.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0011814694153144956,
                    "sentence": "\"Opinion by Rizwan VirkTM & © 2024 Cable News Network, Inc., a Time Warner Company.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009563628700561821,
                    "sentence": "All rights reserved.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 36,
                    "completely_generated_prob": 6.578664755433406e-32
                }
            ],
            "completely_generated_prob": 0.0261024689270432,
            "class_probabilities": {
                "human": 0.9731394009119056,
                "ai": 0.0261024689270432,
                "mixed": 0.0007581301610510362
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9731394009119056,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.0261024689270432,
                    "human": 0.9731394009119056,
                    "mixed": 0.0007581301610510362
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "(CNN) &#8212; In the 1968 film \"2001: A Space Odyssey,\" audiences found themselves staring at one of the first modern depictions of an extremely polite but uncooperative artificial intelligence system, a character named HAL. Given a direct request by the sole surviving astronaut to let him back in the spaceship,HAL responds: \"I'm sorry, Dave. I'm afraid I can't do that.\"Recently, some users found themselves with a similarly (though less dramatic) polite refusal from Gemini, an integratedchatbot and AI assistantthat Google rolled out as a competitor to OpenAI'sChatGPT. When asked, Gemini politely refused in some instances to generate images of historically White people,such as the Vikings.Unlike the fictional HAL, Google's Gemini at leastoffered some explanation, saying that only showing images of White persons would reinforce \"harmful stereotypes and generalizations about people based on their race,\" according to Fox News Digital.The situation quickly erupted, with some critics dubbing it a\"woke\" AI scandal.It didn't help when users discovered that Gemini was creating diverse but historically inaccurate images. When prompted to depict America'sFounding Fathers, for example, it generated an image of a Black man. It also depicteda brown womanas the Pope, andvarious people of color, including a Black man, in Nazi uniformswhen asked to depict a 1943 German soldier.The backlash online was so swift that Google CEO Sundar Pichai admitted that Gemini hadoffended some of its users. Google also hit pause on Gemini's ability to generate people in images. It was presented to the public as a simple oversight done with good intentions gone wrong, withGoogle explaining in a blog postthat \"we tuned it to ensure it doesn't fall into some of the traps we've seen in the past with image generation technology.\"Those \"traps\" - for which Google overcorrected - were of course clear bias in previous AI systems (which are built on the same kinds of tech that Gemini is). These systems had a tendency to showbias against minorities. Facial recognition software didn't always recognize Black people, for example, or evenlabeled themas \"gorillas.\" Loan approval AI algorithmsended up showing bias against minorities. In the image space, if you asked previous AI image generators for an image of a CEO or a doctor, they initiallyalmost always showed images of White males.Ironically,Google was criticized in 2020 for firing a Black AI scientistwho asserted that its AI efforts were biased, and this backlashmay have contributed to the company's overcorrection in the other direction with Gemini. The underlying problem that Google is trying to solve is not an easy one.Historically, many new technological products have shown biases. These can range from howbiomedical devices measure blood oxygen levelsfor different ethnic groups, resulting in underdiagnosis of certain conditions for Black patients, to howsensors don't always register darker-skinned individualsand the lack ofwomen in clinical drug trials.In the case of AI, this problem is exacerbated because of biases that exist in the training data - usually public data on the internet - which the AI tool then learns.The latest scandal, in which Gemini appears to value diversity over historical accuracy, may have uncovered a much bigger issue. If Big Tech organizations such as Google, which have become the new gatekeepers to the world's information, are manipulating historical information based on possible ideological beliefs and cultural edicts, what else are they willing to change? In other words, have Google and other Big Tech companies been manipulating information, including search results, about the present or the past because of ideology, cultures or government censorship?In the 21st century, forget censoring films, burning books or creating propaganda films as forms of information control. Those are so 20th century. Today, if it ain't on Google, it might as well not exist. In this technology-driven world, search engines can be the most effective tool for censorship about the present and the past. To quote a Party slogan from George Orwell's \"1984,\" \"Who controls the past controls the future: who controls the present controls the past.\"As AI becomes more sophisticated, these fears of Big Tech censorship and manipulation of information (with or without the participation of governments) will only grow. Conversational AI such as ChatGPT may already be replacing search as thepreferred method to find and summarize information. BothGoogleandMicrosoftsaw this possibility and jumped all in on AIafter the success of ChatGPT.The possibility even led The Economist to ask, with respect to AI, \"Is Google's 20-year dominance of search in peril?\"Apple has been looking atincorporating OpenAI and more recently, Gemini, into new versions of its iPhones, which would mean significantly more people would use AI on a regular basis.As a professor, I already see this trend firsthand with my students. They often prefer to use ChatGPT not only to find but also to summarize information for them in paragraphs. To the younger generation, because of AI, Web search engines are rapidly becoming as antiquated as physical card catalogs are in libraries today.What makes censorship and manipulation worse with AI is that today's AI already has a well-knownhallucination problem. In other words, sometimes AI makes things up. I learned this fact the hard way when students began turning in obviously AI-generated assignments, complete with references that looked great but had one problem: They didn't actually exist.Given the hallucination problem, whoever the leaders of AI are in the future (whether Google, Microsoft, OpenAI or a new company) will be tempted to \"fill in\" their own rules for what AI should and shouldn't produce, just like Google did with Gemini. This \"filling in\" will inevitably come from the biases and culture of each company and could eventually restrict or at least drastically modify what AI is allowed or is willing to show us, just like Google did with Gemini.That's why this one little scandal goes beyond excessive diversity, equity and inclusion, or DEI, enthusiasm in one company. It may be a portent of what's to come with AI and Big Tech leading us into Orwellian territory. In a few years, you may just want to ask your friendly AI companion to give you some historical information, only to have the AI respond in that maddeningly polite way: \"I'm sorry, Dave. I'm afraid I can't do that.\"Opinion by Rizwan VirkTM & © 2024 Cable News Network, Inc., a Time Warner Company. All rights reserved."
        }
    ]
}