{
    "version": "2025-01-09-base",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0014848840655758977,
                    "sentence": "The progression of mankind's technological capacity has given us new opportunities and conveniences in daily life.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002050168812274933,
                    "sentence": "However, it has also brought new ethical and moral problems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0013302386505529284,
                    "sentence": "One of the most notable technological advancements as of late has beenfacial recognition technology, which is the technology that verifies an individual's identity using a digital image of their face and can be used in a wide range of applications from social media engines to airport surveillance kiosks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001513414434157312,
                    "sentence": "However, this technology has also sparked a number of concerns regarding its use, notably on invasion of privacy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009193053119815886,
                    "sentence": "Examples of this are evidenced through tracking downanti-government protestersor allowing the government to conduct“Big-Brother-like” surveillanceon its citizens.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010523550445213914,
                    "sentence": "Furthermore, there has also been an argument that facial recognition technology discriminates against racial minorities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010901127243414521,
                    "sentence": "A recent2019 U.S. National Institute of Standards and Technology (NIST) studytested every algorithm of two of the most common methods for facial recognition using over 18 million images of 8.49 million people's faces from datasets currently used in U.S. government application.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008757378673180938,
                    "sentence": "The study found some interesting facts about facial recognition technology in the U.S.: the technology had a higher rate of false positive matches for Asian and African American faces; was consistently bad at correctly matching Asian, African American and Native Americans faces compared to Caucasian faces; and had the worst false positive rate for African American women, a group considered to be at the highest risk for being falsely accused of crime according to the study.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007663803407922387,
                    "sentence": "Meanwhile, the NIST study has noted that when compared to their U.S.-based counterparts, facial recognition algorithms developed in Asian countries produced “very little” difference in false positives between Asian and Caucasian faces.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0013301610015332699,
                    "sentence": "Furthermore, there have been other studies in the past that also pointed out possible technological flaws in facial recognition technology.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009945014026015997,
                    "sentence": "A2003 NIST reportshowed that female subjects were more difficult for algorithms to recognize than male subjects.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0013028093380853534,
                    "sentence": "A2018 studyby researchers from MIT and Microsoft demonstrated similar findings where the commercial gender classification system had up to a 34.7% error rate for darker-skinned females while a maximum error rate for light-skinned males was only 0.8%.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0015344955027103424,
                    "sentence": "It also found that the dataset used by facial analysis benchmarks was overwhelmingly composed of lighter-skinned subjects.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001740604406222701,
                    "sentence": "These findings could be used to supportopponents of the Lockport City School District's planto adopt facial recognition cameras in its buildings for “security reasons.” Dr. Robert LiPuma, the Lockport City School District's technology director, and other proponents of the technology argue that it will prevent mass shootings like the one at Marjory Stoneman Douglas High and sexual predators from entering school premises.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001523008686490357,
                    "sentence": "However, opponents of the technology ᅳ including concerned parents ᅳargue thatthe new system will have a series of privacy, accuracy and racial bias issues.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0014190671499818563,
                    "sentence": "They have used records to point out that SN Technologies, the company contracted by the district to install the system in Lockport City schools, has numerous technical issues with its facial recognition systemmisidentifying African American facesand weapons detection system misidentifying several objects as firearms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0011956115486100316,
                    "sentence": "Opponents worry that the newly adopted and inaccurate facial recognition system could trigger an undesirable armed police response against Black students that comprise 11% of Lockport City schools.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001027368358336389,
                    "sentence": "This resonates withclaims made by the ACLUagainst the technology that it is very likely to be disadvantageous towards African American people due to the police database being composed of a plurality of their images and disproportionately high numbers of security cameras installed in their neighborhoods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001024520955979824,
                    "sentence": "Should this technology be deployed in any further capacity if it is directly biased against minorities?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001056304550729692,
                    "sentence": "Possibly.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0012295851483941078,
                    "sentence": "If the technology works out its kinks and gains more foothold in crime investigation and other security-related proceedings, it has the potential to show someone is truly innocent in the absence of hard evidence in their favor.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001326880301348865,
                    "sentence": "Although the2019 NIST studyprovided some encouraging recommendations that the right algorithms and development processes could “entirely eliminate” bias, technological advancement usually takes a considerable amount of time to bear fruit.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001312409178353846,
                    "sentence": "Technology, such as facial recognition, has important implications for people's daily lives, especially in racially-diverse U.S. Until it can be proven to be fair and equitable towards all, people at the community's helm should be more cautious in adopting the technology in its current state.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00505432952195406,
                    "sentence": "Sangho Seog is an Opinion Intern for the fall 2020 quarter.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008428921923041344,
                    "sentence": "He can be reached atsseog@uci.edu.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.00010005932717626924
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                }
            ],
            "completely_generated_prob": 0.016657189493782178,
            "class_probabilities": {
                "human": 0.9830528455613092,
                "ai": 0.016657189493782178,
                "mixed": 0.0002899649449086031
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9830528455613092,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.016657189493782178,
                    "human": 0.9830528455613092,
                    "mixed": 0.0002899649449086031
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The progression of mankind’s technological capacity has given us new opportunities and conveniences in daily life. However, it has also brought new ethical and moral problems. One of the most notable technological advancements as of late has beenfacial recognition technology, which is the technology that verifies an individual’s identity using a digital image of their face and can be used in a wide range of applications from social media engines to airport surveillance kiosks.\nHowever, this technology has also sparked a number of concerns regarding its use, notably on invasion of privacy. Examples of this are evidenced through tracking downanti-government protestersor allowing the government to conduct“Big-Brother-like” surveillanceon its citizens. Furthermore, there has also been an argument that facial recognition technology discriminates against racial minorities.\nA recent2019 U.S. National Institute of Standards and Technology (NIST) studytested every algorithm of two of the most common methods for facial recognition using over 18 million images of 8.49 million people’s faces from datasets currently used in U.S. government application. The study found some interesting facts about facial recognition technology in the U.S.: the technology had a higher rate of false positive matches for Asian and African American faces; was consistently bad at correctly matching Asian, African American and Native Americans faces compared to Caucasian faces; and had the worst false positive rate for African American women, a group considered to be at the highest risk for being falsely accused of crime according to the study. Meanwhile, the NIST study has noted that when compared to their U.S.-based counterparts, facial recognition algorithms developed in Asian countries produced “very little” difference in false positives between Asian and Caucasian faces.\nFurthermore, there have been other studies in the past that also pointed out possible technological flaws in facial recognition technology. A2003 NIST reportshowed that female subjects were more difficult for algorithms to recognize than male subjects. A2018 studyby researchers from MIT and Microsoft demonstrated similar findings where the commercial gender classification system had up to a 34.7% error rate for darker-skinned females while a maximum error rate for light-skinned males was only 0.8%. It also found that the dataset used by facial analysis benchmarks was overwhelmingly composed of lighter-skinned subjects.\nThese findings could be used to supportopponents of the Lockport City School District’s planto adopt facial recognition cameras in its buildings for “security reasons.” Dr. Robert LiPuma, the Lockport City School District’s technology director, and other proponents of the technology argue that it will prevent mass shootings like the one at Marjory Stoneman Douglas High and sexual predators from entering school premises. However, opponents of the technology — including concerned parents —argue thatthe new system will have a series of privacy, accuracy and racial bias issues. They have used records to point out that SN Technologies, the company contracted by the district to install the system in Lockport City schools, has numerous technical issues with its facial recognition systemmisidentifying African American facesand weapons detection system misidentifying several objects as firearms. Opponents worry that the newly adopted and inaccurate facial recognition system could trigger an undesirable armed police response against Black students that comprise 11% of Lockport City schools. This resonates withclaims made by the ACLUagainst the technology that it is very likely to be disadvantageous towards African American people due to the police database being composed of a plurality of their images and disproportionately high numbers of security cameras installed in their neighborhoods.\nShould this technology be deployed in any further capacity if it is directly biased against minorities? Possibly. If the technology works out its kinks and gains more foothold in crime investigation and other security-related proceedings, it has the potential to show someone is truly innocent in the absence of hard evidence in their favor.\nAlthough the2019 NIST studyprovided some encouraging recommendations that the right algorithms and development processes could “entirely eliminate” bias, technological advancement usually takes a considerable amount of time to bear fruit. Technology, such as facial recognition, has important implications for people’s daily lives, especially in racially-diverse U.S. Until it can be proven to be fair and equitable towards all, people at the community’s helm should be more cautious in adopting the technology in its current state.\nSangho Seog is an Opinion Intern for the fall 2020 quarter. He can be reached atsseog@uci.edu.\n"
        }
    ]
}